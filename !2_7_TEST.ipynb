{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "!2-7.TEST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJjYkzcAg6PVXb2PZya6Iy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dia2teen/first_project/blob/master/!2_7_TEST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEweuRHyfUab"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pytorch_lightning\n",
        "!pip install -q monai"
      ],
      "metadata": {
        "id": "HhcI6QmW-Cbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "2BRJLxzt9Z_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.get_device_name(0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HFy-cR2l9Z8U",
        "outputId": "3362da5b-2422-49a6-f4f2-b482fd77fd24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "import monai\n",
        "import h5py"
      ],
      "metadata": {
        "id": "uxlCSEL69Z4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!if [ ! -e seq.h5 ]; then wget https://github.com/japan-medical-ai/medical-ai-course-materials/releases/download/v0.1/seq.h5; fi"
      ],
      "metadata": {
        "id": "knI6i1Yk9Z1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データの読み込み\n",
        "with h5py.File('seq.h5', 'r') as hf:\n",
        "    x_train, t_train = hf['train_in'][()], hf['train_out'][()]\n",
        "    x_val, t_val = hf['valid_in'][()], hf['valid_out'][()]\n",
        "    x_test, t_test = hf['test_in'][()], hf['test_out'][()]\n",
        "    label = hf['target_labels'][()]"
      ],
      "metadata": {
        "id": "q8afG3SE9Zxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SequenceDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, x, t):\n",
        "        self.x = x\n",
        "        self.t = t[:, :, 1]  # 今回は 2 つ目の実験結果のカバレッジ値のみ使用\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.x[idx], dtype=torch.float32).permute(1, 0)\n",
        "        t = torch.tensor(self.t[idx], dtype=torch.float32)\n",
        "        return x, t\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ],
      "metadata": {
        "id": "jneWR_c99Zt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# シードを固定\n",
        "pl.seed_everything(0)\n",
        "\n",
        "# データセットの取得\n",
        "train = SequenceDataset(x_train, t_train)\n",
        "val = SequenceDataset(x_val, t_val)\n",
        "test = SequenceDataset(x_test, t_test)\n",
        "\n",
        "# バッチサイズの定義\n",
        "batch_size = 64\n",
        "\n",
        "# Data Loader を定義\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True, drop_last=True)\n",
        "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA9Ldpsl9ZqD",
        "outputId": "6841e060-2dd8-43f3-f67b-f1b0886a318e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.networks.blocks import Convolution\n"
      ],
      "metadata": {
        "id": "qZn1z-Xb9Zim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q optuna\n",
        "import optuna\n",
        "optuna.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "q-IYXRI4IeIi",
        "outputId": "0c1034a4-7db6-4194-f041-ac5bed15f3a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "IGxsNrDP9ZMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net2(pl.LightningModule):\n",
        "\n",
        "    def __init__(self,step_size=800, gamma=0.3):\n",
        "        super().__init__()\n",
        "        self.step_size = step_size\n",
        "        self.gamma = gamma\n",
        "\n",
        "        self.squeeze_params = [\n",
        "            {'in_channels': 4,  'out_channels': 28,  'kernel_size': 21, 'strides': 2},\n",
        "            {'in_channels': 28, 'out_channels': 52,  'kernel_size': 7,  'strides': 4},\n",
        "            {'in_channels': 52, 'out_channels': 76,  'kernel_size': 7,  'strides': 4},\n",
        "            {'in_channels': 76, 'out_channels': 100, 'kernel_size': 7,  'strides': 4},\n",
        "        ]\n",
        "\n",
        "        self.dilated_conv_params = [\n",
        "            {'in_channels': 100, 'out_channels': 24, 'kernel_size': 3, 'dilation': 1},\n",
        "            {'in_channels': 124, 'out_channels': 24, 'kernel_size': 3, 'dilation': 2},\n",
        "            {'in_channels': 148, 'out_channels': 24, 'kernel_size': 3, 'dilation': 4},\n",
        "            {'in_channels': 172, 'out_channels': 24, 'kernel_size': 3, 'dilation': 8},\n",
        "            {'in_channels': 196, 'out_channels': 24, 'kernel_size': 3, 'dilation': 16},\n",
        "            {'in_channels': 220, 'out_channels': 24, 'kernel_size': 3, 'dilation': 32},\n",
        "        ]\n",
        "\n",
        "        # Squeeze Block\n",
        "        self.squeeze = nn.Sequential()\n",
        "        for (i, p) in enumerate(self.squeeze_params):\n",
        "            layer = Convolution(\n",
        "                      dimensions=1,\n",
        "                      in_channels=p['in_channels'], out_channels=p['out_channels'],\n",
        "                      kernel_size=p['kernel_size'], strides=p['strides'],\n",
        "                      norm='batch', act='ReLu')\n",
        "            self.squeeze.add_module(f'conv{i+1}', layer)\n",
        "\n",
        "        # Dilated Block\n",
        "        self.dilated_conv = nn.Sequential()\n",
        "        for (i, p) in enumerate(self.dilated_conv_params):\n",
        "            layer = Convolution(\n",
        "                      dimensions=1,\n",
        "                      in_channels=p['in_channels'], out_channels=p['out_channels'],\n",
        "                      kernel_size=p['kernel_size'], dilation=p['dilation'],\n",
        "                      norm='batch', act='ReLU')\n",
        "            self.dilated_conv.add_module(f'conv_{i+1}', layer)\n",
        "\n",
        "        # Convolution\n",
        "        self.conv = nn.Conv1d(in_channels=244, out_channels=1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Squeeze Block\n",
        "        h = self.squeeze(x)\n",
        "        # Dilated Block\n",
        "        hs = [h]\n",
        "        for layer in self.dilated_conv:\n",
        "            h = torch.cat(hs, dim=1)\n",
        "            h = layer(h)\n",
        "            hs.append(h)\n",
        "        # Convolution\n",
        "        h = torch.cat(hs, dim=1)\n",
        "        h = self.conv(h)\n",
        "        h = h.squeeze()\n",
        "        return h\n",
        "\n",
        "    def r2_score(self, y, t):\n",
        "        y = torch.exp(y)\n",
        "        r_n = ((t - y)**2).sum(dim=0)\n",
        "        r_d = ((t - t.mean(dim=0))**2).sum(dim=0)\n",
        "        r = 1 - r_n / r_d\n",
        "        return r.mean()\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, t = batch\n",
        "        y = self(x)\n",
        "        loss = F.poisson_nll_loss(y, t)\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
        "        self.log('train_r2', self.r2_score(y, t), on_step=True, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, t = batch\n",
        "        y = self(x)\n",
        "        loss = F.poisson_nll_loss(y, t)\n",
        "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
        "        self.log('val_r2', self.r2_score(y, t), on_step=False, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, t = batch\n",
        "        y = self(x)\n",
        "        loss = F.poisson_nll_loss(y, t)\n",
        "        self.log('test_loss', loss, on_step=False, on_epoch=True)\n",
        "        self.log('test_r2', self.r2_score(y, t), on_step=False, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters())\n",
        "        # scheduler を追加\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = self.step_size, gamma = self.gamma)\n",
        "        return [optimizer], [scheduler] #2つを返すようにする\n"
      ],
      "metadata": {
        "id": "PNq_iAF6Hl7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial): \n",
        "\n",
        "  # ハイパーパラメータの候補\n",
        "  step_size = trial.suggest_int('step_size', 100, 800)\n",
        "  gamma = trial.suggest_loguniform('gamma', 1e-5, 1e-1)\n",
        "\n",
        "  # ネットワークの訓練（早期終了あり）\n",
        "  pl.seed_everything(0)\n",
        "  net2 = Net2(step_size, gamma)\n",
        "  trainer2 = pl.Trainer(max_epochs=10, gpus=1, deterministic=True, callbacks=[EarlyStopping(monitor='val_r2')])\n",
        "  trainer2.fit(net2, train_loader, val_loader)\n",
        "  result = trainer2.callback_metrics['val_r2'] \n",
        "\n",
        "  # 検証データの accuracy で評価\n",
        "  return result"
      ],
      "metadata": {
        "id": "-LGWmF_u9ZIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# study オブジェクトを作成し、最適化を実行\n",
        "sampler = optuna.samplers.TPESampler(seed=0)\n",
        "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
        "study.optimize(objective, n_trials=10)"
      ],
      "metadata": {
        "id": "DLiNHHjV9ZE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_params"
      ],
      "metadata": {
        "id": "a9TSXOVx9ZBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_value"
      ],
      "metadata": {
        "id": "F1Haz4179Y9h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}